---
title: Project Support Centre Monthly Reporting (Draft)
subtitle: Streamlining report creation using R workflows
short_title: PSC Reporting

author:  Tristan Louth-Robins
affiliation: CSIRO Finance 
photo: resources/img/TLR.jpeg

output: 
  DSreport::project_summary:
    self_contained: no
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(
  results = 'asis',
  echo = FALSE,
  warning = FALSE,
  message = FALSE,
  fig.align = 'center'
)

#Load libraries
library(tidyverse)
library(gganimate)
library(gifski)
library(gridExtra)
library(kableExtra)
```


# Introduction
I joined CSIRO in 2009 and worked in the Contract Administration Centre until 2014. Since then, I've covered a variety of roles supporting Project Support, In-Business Finance, Research Office and currently the Project Support Centre (Corporate Finance.) Prior to commencing Data School I could code in HTML and a bit of C, but its applications were largely restricted to extra-curricular activities away from CSIRO. Learning R and aspect of Data Management appealed to me as an attractive and valuable skill that could be applied in practice for the purposes of reporting, file management systems and general compliance activities.

# My Project

#### From manual input to R workflow

This project could be best regarded as an attempt to replicate a process that is currently handled manually and consists of two primary components: 1) data import, wrangling and tidying; 2) visualisation and communication. 


#### The PSC Monthly report

This process is part of preparing data the Project Support Centre (PSC) monthly report. The PSC monthly summary reports on the status of open and completed tasks, recorded across JIRA and O2D. These statuses inform part of the larger Finance Support Centre reporting at month's end.


#### Issues with the manual process

One of the present issues with preparation of the PSC report is that it is currently a manual process and is both time-consuming and potentially prone to data duplication and human errors. Therefore, I felt that R could have the potential to efficiently wrangle, tidy and tranform JIRA and O2D data, resulting in accurate reporting data.


#### The R workflow: replicating a manual process in Excel

In order to take this manual process and realise it as an R workflow, I would need to take the manual work currently done in Excel (copy/paste, filtering, pivot tables, cell references, etc) and replicate this as R code, employing a number of functions and successive dataframes to ensure the data was going to the right place.  

#### Wrangling, tidying, transforming

The goal of the main R workflow was to wrangle large chunks of data - extracted from JIRA nad O2D - and transform this into concise summaries of open and completed JIRA and O2D tasks for each month. From here, the summaries are brought together with previous month data and comprise a complete summary of the Financial Year-To-Date. For the purposes of the PSC report, only the open statuses need to be reported upon.

## Preliminary results

#### Visualisation of data

The following table and plot are the key components of the PSC Monthly Report, and form the basis of its presentation. 

To present this data in Markdown, I have utilised internal R Markdown code to read in the data summary generated from my R workflow, assigned new variables and used these as datatables for table and plots details open PSC tasks across the 2019-20 FY.


```{r}

# Read in final report summary. This has been duplicated from the data/outputs directory in the R project and put into the Markdown directory: resources/final.csv.

PSC_bind <- read_csv("resources/final.csv")

# Tibbles for generation of plots: 1) Open PSC tasks; 2) Completed PSC tasks; 3) Combined PSC tasks.

PSC_open_gathered <-  
  select(PSC_bind, -3,-5,-7,-9,-11,-13,-15,-16:-18) %>% 
  rename("Planning Tool Changes" = MPTC_open, 
         "New Project Created" = MNPC_open,
         "Project Leader Authorisation" = MPLA_open,
         "Other Tasks" = MOT_open,
         "Billing & Progress MS; Revenue Recognition" = MBPM_RR_open,
         "Close Project/Stage" = MCPS_open,
         "Project Date Changes" = MPDC_open) %>% 
  gather(2:8 , key = 'Task', value = 'n') %>% 
  mutate(Status = "open")

PSC_comp_gathered <- 
  select(PSC_bind, -2,-4,-6,-8,-10,-12,-14,-16:-18) %>% 
  rename("Planning Tool Changes" = MPTC_comp, 
         "New Project Created" = MNPC_comp,
         "Project Leader Authorisation" = MPLA_comp,
         "Other Tasks" = MOT_comp,
         "Billing & Progress MS; Revenue Recognition" = MBPM_RR_comp,
         "Close Project/Stage" = MCPS_comp,
         "Project Date Changes" = MPDC_comp) %>% 
  gather(2:8, key = 'Task', value = 'n') %>% 
  mutate(Status = "completed")

PSC_combined <- full_join(PSC_open_gathered, PSC_comp_gathered)

# Rearranged tibble for long data summary (Open PSC Tasks) for visualisation as a table.

PSC_open_long <-  
  select(PSC_bind, -3,-5,-7,-9,-11,-13,-15,-16:-18) %>% 
  rename("Planning Tool Changes" = MPTC_open, 
         "New Project Created" = MNPC_open,
         "Project Leader Authorisation" = MPLA_open,
         "Other Tasks" = MOT_open,
         "Billing & Progress MS; Revenue Recognition" = MBPM_RR_open,
         "Close Project/Stage" = MCPS_open,
         "Project Date Changes" = MPDC_open) %>% 
  gather(2:8, key = 'Task', value = 'n') %>% 
  spread(1, key = 'month', value = 'n') %>% 
  arrange(Task) %>% 
  rename("2019-20 FY" = Task,
         "Jul" = `2019-07-01`,
         "Aug" = `2019-08-01`,
         "Sep" = `2019-09-01`,
         "Oct" = `2019-10-01`,
         "Nov" = `2019-11-01`,
         "Dec" = `2019-12-01`,
         "Jan" = `2020-01-01`,
         "Feb" = `2020-02-01`,
         "Mar" = `2020-03-01`,
         "Apr" = `2020-04-01`,
         "May" = `2020-05-01`,
         "Jun" = `2020-06-01`) 

# generate a table of Open PSC Tasks based on the long data tibble.

knitr::kable(head(PSC_open_long, n = 7), format = "html", caption = " ") %>% 
  kable_styling("striped")

```


```{r standard-plot, out.width='80%', fig.align='left', fig.height= 4, fig.width=8, fig.cap="Table summary of open PSC tasks for 2019-20 FY (up to April 2020)"}

PSC_open <- PSC_open_gathered %>% 
  ggplot(aes(x = month, y = n, fill = Task)) +
  geom_col() +
  scale_fill_brewer(palette = "Paired") +
  labs(
    title = "Open PSC tasks: 2019-20 FY (up to Apr-20)",
    x = "Month",
    y = "Count",
    colour = "Task"
  ) + 
  theme_bw() +
  theme(
    panel.grid.minor = element_blank(),
    plot.title = element_text(face = "bold")
  ) 

PSC_open <- PSC_open +
  theme(axis.text.x = element_text(angle = 50, size = 10, vjust = 0.5))

PSC_open


```


#### Animation of plots

The following is an animation of the above chart. I think the animated aspect lends greater insight into task volume over the course of the year and is indicative of particular trends, especially prior to and following the EOFY period.

The animation incorporates `transition_time()` and `shadow_mark()` functions, whilst an `ease_aes()` function smooths the transitions. The timing of the animation is controlled further by rendering the animation using the `animate()` function.

![](resources/img/PSC_open.gif){height=400px, width=800px}

Although this next animation is less useful for the purposes of reporting, I thought it would be interesting to examine both open and completed task statuses transitioned over each month, utilising a `facetwrap()` function to position each task status side-by-side for comparison. A potential improvement to the animated plot could be to fix the date stamp and replace this with the name of the month following each transition state.

![](resources/img/PSC_combined.gif){height=500px, width=500px}

# My Digital Toolbox (TBC)

What digital tools have you been using in your project? Do you expect that everything will be able 
to be completed within R, or will you need to work with multiple tools to get the right result?
Which of the digital skills needed for your project have you learned since starting Data School?

You can use all the usual R markdown features in writing a project summary, including lists:

* R - dplyr, ggplot, ...
* Python
* SQL

# My time went ... 

The most labour-intensive aspect of this project involved analysing the current (manual) report process and transposing this into an R workflow. 

Because so much of the manual process involves hands-on copying/pasting, substituting of fields, filtering, creating pivot table summaries and so forth, the major challenge was identifying the best approach in R, using the experience I'd gained to date.

At times this process was incredibly frustrating, though I found that most of the issues could be overcome by taking a step back and thinking about a particular part of the process in the simplest possible way. Asking lots of questions helped as well! When worst came to worst, I'd simpley get a large sheet of paper out and draw out the process for the upteenth time. Once I was immersed back in the code, tried and true functions such as `filter()`, `split()`, `select()`, `mutate()`, `rename()`, `group_by()` and `summarise()` were indispensable. 

# Next steps

Although I managed to get the project up to the point where the workflow process executed perfectly (and accurately!), I would have really liked to reduce the volume of code in my script and find more efficient ways of performing certain functions. Duplication was an ongoing concern, and particular care needed to be taken to avoid errors.

Looking ahead, I like to spend more time creating my own functions to avoid duplicated code as well as exploring Regular Expressions, strings and interation in greater detail. Above all, spending more time with the general theory of R is of great interest to me, insofar that I recently purchase the R For Data Science book for my iPad!

Beyond R itself, becoming accustomed with other principles of Data Science and Data Management during this course has been enormously beneficial and I imagine that this will have valuable applications for myself and the rest of my Team in Finance.

# My Data School Experience

text text text text text text 


This summary is mostly about your project. However we would also like to hear about other
parts of your Data School experience. What aspects of the program did you really enjoy? Have you
tried applying the skills you have learned in your daily work? Have you been able to transfer this 
knowledge to your team members? Any descriptions of the personal impact the program has 
had are welcome here as well!

# Thank you:

Stephen, Kerensa, Kristian, Helpers, Dan Nguyen [...]